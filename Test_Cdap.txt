Test GIT ajout d'une ligne 

# Version CDAP :  Version 5.1.2


#####################################
# Info Conf MCO pour le namespoGgace 
#####################################

hdfs.root.url	Namespace	hdfs://hdfs://PTF-cluster8020
kafka.brokers	Namespace	vm-zk-2.novalocal:6667,vm-zk-3.novalocal:6667,vm-zk-1.novalocal:6667
postgres.jdbc.password	Namespace	sopra123
postgres.jdbc.url	Namespace	jdbc:postgresql://172.18.0.4:5432/ais_db
postgres.jdbc.user	Namespace	ais
redis.catalog	Namespace	geomesa
redis.host	Namespace	172.18.0.8
redis.port	Namespace	6379
redis.url	Namespace	redis://172.18.0.8:6379
zookeepers	Namespace	vm-zk-1.novalocal:2181,vm-zk-2.novalocal:2181,vm-zk-3.novalocal:2181

# Execution d'un job spark simple (spark 2) :

export SPARK_MAJOR_VERSION=2
spark-submit --class org.apache.spark.examples.SparkPi --deploy-mode client --master yarn --driver-memory 1g --executor-memory 1g --executor-cores 1 --queue default /data/usr/hdp/2.6.5.0-292/spark2/examples/jars/spark-examples_2.*.jar 10
Pi is roughly 3.142015142015142



# Exec Spark Word Count jar

spark-submit --class com.cloudera.sparkwordcount.SparkWordCount --master yarn --deploy-mode client --executor-memory 1g --name wordcount --conf "spark.app.id=wordcount" sparkwordcount-0.0.1-SNAPSHOT.jar hdfs://PTF-cluster/PSCDATA/CDAP_PSCTEST/readstream/list_word.txt 2



// scalastyle:off println
package sofiane.cdap.test

import org.apache.spark.sql.SparkSession

/** Computes an approximation to pi */
object CdapRW {
  def main(args: Array[String]) {
    val spark = SparkSession.builder.appName("Spark cdap 1").getOrCreate()
    
	val csvFile = spark.read.format("csv").option("header", "false").option("mode", "FAILFAST").option("inferSchema", "true").load("hdfs://PTF-cluster/PSCDATA/CDAP_PSCTEST/readstream/list_word.txt");
	csvFile.write.mode("overwrite").option("sep", "------").save("hdfs://PTF-cluster/PSCDATA/CDAP_PSCTEST/readstream/list_word.csv");  
    
    spark.stop()
  }
}
// scalastyle:on println

##############
# AWS        #
##############

